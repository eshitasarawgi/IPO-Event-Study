{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26c1bb7-ad4a-4ed2-ab19-c5ff2500827b",
   "metadata": {},
   "source": [
    "5. Enriched Hypotheses tested in this notebook which aims to answer the following 3 questions:\n",
    "   \n",
    "   (a) Do high-subscription IPOs consistently show first-day pops (gains)?\n",
    "\n",
    "\n",
    "   (b) Does listing-day premium sustain over a 30 day window?\n",
    "\n",
    "\n",
    "   (c) Are retail-heavy IPOs more volatile post listing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8888fa-b2c9-41b5-91b5-77adc9490402",
   "metadata": {},
   "source": [
    "5.1 Import of Final Datasets and Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9baacde-fd8f-4459-ac9d-d05de620e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and cleaned. Shape:  (39, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>listing_date</th>\n",
       "      <th>subscription_category</th>\n",
       "      <th>issue_open</th>\n",
       "      <th>issue_close</th>\n",
       "      <th>issue_price</th>\n",
       "      <th>issue_size</th>\n",
       "      <th>retail_pct</th>\n",
       "      <th>qib_pct</th>\n",
       "      <th>sector</th>\n",
       "      <th>notes</th>\n",
       "      <th>ipo_year</th>\n",
       "      <th>log_issue_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>IRCTC</td>\n",
       "      <td>IRCTC.NS</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>Low</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>320</td>\n",
       "      <td>645.0000</td>\n",
       "      <td>112.2600</td>\n",
       "      <td>53.8900</td>\n",
       "      <td>Railway Services</td>\n",
       "      <td>Indian Railways subsidiary; actually high sub</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.4693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fino Payments Bank</td>\n",
       "      <td>FINOPB.NS</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>Low</td>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>577</td>\n",
       "      <td>1200.0000</td>\n",
       "      <td>2.2800</td>\n",
       "      <td>3.3500</td>\n",
       "      <td>Fintech - Banking</td>\n",
       "      <td>Payments bank</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Indiamart Intermesh</td>\n",
       "      <td>INDIAMART.NS</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>Low</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>973</td>\n",
       "      <td>475.0000</td>\n",
       "      <td>36.0900</td>\n",
       "      <td>46.5500</td>\n",
       "      <td>B2B Marketplace</td>\n",
       "      <td>B2B e-commerce platform</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Stanley Lifestyles</td>\n",
       "      <td>STANLEY.NS</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>369</td>\n",
       "      <td>537.0200</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>Furniture - Premium</td>\n",
       "      <td>Luxury furniture manufacturer</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Akums Drugs</td>\n",
       "      <td>AKUMS.NS</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>679</td>\n",
       "      <td>1857.0000</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>3.4500</td>\n",
       "      <td>Pharmaceuticals - CDMO</td>\n",
       "      <td>Contract manufacturing</td>\n",
       "      <td>2024</td>\n",
       "      <td>7.5267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company_name        ticker listing_date subscription_category  \\\n",
       "34                IRCTC      IRCTC.NS   2019-10-14                   Low   \n",
       "35   Fino Payments Bank     FINOPB.NS   2021-10-29                   Low   \n",
       "36  Indiamart Intermesh  INDIAMART.NS   2019-07-04                   Low   \n",
       "37   Stanley Lifestyles    STANLEY.NS   2024-06-28                   Low   \n",
       "38          Akums Drugs      AKUMS.NS   2024-07-31                   Low   \n",
       "\n",
       "   issue_open issue_close  issue_price  issue_size  retail_pct  qib_pct  \\\n",
       "34 2019-09-30  2019-10-03          320    645.0000    112.2600  53.8900   \n",
       "35 2021-10-19  2021-10-21          577   1200.0000      2.2800   3.3500   \n",
       "36 2019-06-24  2019-06-26          973    475.0000     36.0900  46.5500   \n",
       "37 2024-06-21  2024-06-25          369    537.0200      2.6000   3.7800   \n",
       "38 2024-07-30  2024-08-01          679   1857.0000      2.2500   3.4500   \n",
       "\n",
       "                    sector                                          notes  \\\n",
       "34        Railway Services  Indian Railways subsidiary; actually high sub   \n",
       "35       Fintech - Banking                                  Payments bank   \n",
       "36         B2B Marketplace                        B2B e-commerce platform   \n",
       "37     Furniture - Premium                  Luxury furniture manufacturer   \n",
       "38  Pharmaceuticals - CDMO                         Contract manufacturing   \n",
       "\n",
       "    ipo_year  log_issue_size  \n",
       "34      2019          6.4693  \n",
       "35      2021          7.0901  \n",
       "36      2019          6.1633  \n",
       "37      2024          6.2860  \n",
       "38      2024          7.5267  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "META_PATH = \"IPO_META/ipo_metadata_enriched.csv\"\n",
    "df = pd.read_csv(META_PATH)\n",
    "\n",
    "\n",
    "#Standard Cleaning Procedures\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "df[\"listing_date\"] = pd.to_datetime(df[\"listing_date\"])\n",
    "df[\"issue_open\"] = pd.to_datetime(df[\"issue_open\"])\n",
    "df[\"issue_close\"] = pd.to_datetime(df[\"issue_close\"])\n",
    "\n",
    "#Creating 'control' variables\n",
    "df[\"ipo_year\"] = df[\"listing_date\"].dt.year\n",
    "df[\"log_issue_size\"] = np.log(df[\"issue_size\"])\n",
    "\n",
    "print(\"Dataset loaded and cleaned. Shape: \", df.shape)\n",
    "df.head()\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28e64f-433b-462c-81a1-9fa45e047a7b",
   "metadata": {},
   "source": [
    "5.2 Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06863c8a-e0f6-4759-8ff1-ac6c255f8d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>subscription_category</th>\n",
       "      <th>high_sub_dummy</th>\n",
       "      <th>issue_size</th>\n",
       "      <th>log_issue_size</th>\n",
       "      <th>qib_pct</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAMATA.NS</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>179.3100</td>\n",
       "      <td>5.1891</td>\n",
       "      <td>72.3500</td>\n",
       "      <td>Machinery Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNIMECH.NS</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0700</td>\n",
       "      <td>6.2147</td>\n",
       "      <td>68.2500</td>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOBIKWIK.NS</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>572.0000</td>\n",
       "      <td>6.3491</td>\n",
       "      <td>45.3200</td>\n",
       "      <td>Fintech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENORES.NS</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>582.4800</td>\n",
       "      <td>6.3673</td>\n",
       "      <td>85.4500</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRANSRAILL.NS</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>839.2300</td>\n",
       "      <td>6.7325</td>\n",
       "      <td>76.8900</td>\n",
       "      <td>Railway Equipment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ticker subscription_category  high_sub_dummy  issue_size  \\\n",
       "0      MAMATA.NS                  High               1    179.3100   \n",
       "1     UNIMECH.NS                  High               1    500.0700   \n",
       "2    MOBIKWIK.NS                  High               1    572.0000   \n",
       "3     SENORES.NS                  High               1    582.4800   \n",
       "4  TRANSRAILL.NS                  High               1    839.2300   \n",
       "\n",
       "   log_issue_size  qib_pct                   sector  \n",
       "0          5.1891  72.3500  Machinery Manufacturing  \n",
       "1          6.2147  68.2500      Aerospace & Defense  \n",
       "2          6.3491  45.3200                  Fintech  \n",
       "3          6.3673  85.4500          Pharmaceuticals  \n",
       "4          6.7325  76.8900        Railway Equipment  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subscription Dummy\n",
    "df[\"high_sub_dummy\"] = df[\"subscription_category\"].apply(lambda x : 1 if x == \"High\" else 0 )\n",
    "\n",
    "#Ensure numeric columns are numeric\n",
    "numeric_cols = [\"issue_price\", \"issue_size\", \"retail_pct\", \"qib_pct\"]\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)\n",
    "\n",
    "df[\"sector\"] = df[\"sector\"].astype(\"category\")\n",
    "\n",
    "\n",
    "df[[\"ticker\",\"subscription_category\", \"high_sub_dummy\", \"issue_size\", \"log_issue_size\", \"qib_pct\", \"sector\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bad14f6-707a-4b90-837e-e6b61fa022ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled returns data loaded. Shape:  (40, 8)\n",
      "IPOs with day1_return: 24\n",
      "Final merged dataset shape: (38, 19)\n",
      "Successfully merged IPOs: 38\n",
      "\n",
      "Subscription category check:\n",
      "  From metadata (high_sub_dummy): 19 high\n",
      "  From pooled (subscription_cat): 19 high\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.float_format', lambda x : f'{x: .4f}')\n",
    "\n",
    "POOLED_PATH = \"IPO_Meta/meta_output_processed.csv/df_pooled_master.csv\"\n",
    "df_pooled = pd.read_csv(POOLED_PATH)\n",
    "\n",
    "df_pooled.columns = df_pooled.columns.str.lower().str.strip()\n",
    "df_pooled[\"listing_date\"] = pd.to_datetime(df_pooled[\"listing_date\"])\n",
    "\n",
    "print (\"Pooled returns data loaded. Shape: \", df_pooled.shape)\n",
    "print(\"IPOs with day1_return:\", df_pooled['day1_return'].notna().sum())\n",
    "\n",
    "df_final = df.merge(\n",
    "    df_pooled[['ticker', 'day1_return', 'car_30', 'vol_30', 'subscription_cat']], \n",
    "    on = 'ticker',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "print(f\"Final merged dataset shape: {df_final.shape}\")\n",
    "print(f\"Successfully merged IPOs: {len(df_final)}\")\n",
    "print(f\"\\nSubscription category check:\")\n",
    "print(f\"  From metadata (high_sub_dummy): {df_final['high_sub_dummy'].sum()} high\")\n",
    "print(f\"  From pooled (subscription_cat): {(df_final['subscription_cat'] == 'High').sum()} high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cffd34d6-32fc-4a60-9bda-bdb67f583eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "================================================================================\n",
      "Total IPOs: 39\n",
      "High Subscription IPOs: 20 (51.3%)\n",
      "Retail-Heavy IPOs: 19 (48.7%)\n"
     ]
    }
   ],
   "source": [
    "if 'subscription_times' in df.columns:\n",
    "    df['subscription_numeric'] = pd.to_numeric(\n",
    "        df['subscription_times'].astype(str).str.replace('x', '').str.strip(), \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "# Create retail dominance flag (retail > 50%)\n",
    "df['retail_heavy'] = (df['retail_pct'] > 50).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total IPOs: {len(df)}\")\n",
    "print(f\"High Subscription IPOs: {df['high_sub_dummy'].sum()} ({df['high_sub_dummy'].mean()*100:.1f}%)\")\n",
    "print(f\"Retail-Heavy IPOs: {df['retail_heavy'].sum()} ({df['retail_heavy'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad901d-ce79-47a1-be42-f5e84f711ab5",
   "metadata": {},
   "source": [
    "5.3 Fixtures Before Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2282706-3e7f-46b1-80d0-76ba152dac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STANDARDIZING TICKER FORMATS\n",
      "================================================================================\n",
      "Metadata unique tickers: 39\n",
      "Pooled unique tickers: 40\n",
      "\n",
      "✓ Merged on base ticker\n",
      "✓ Final dataset: 39 IPOs\n",
      "⚠️  Still missing 1 IPO - investigating...\n",
      "Missing ticker(s): {'IXIGO'}\n",
      "IXIGO: in metadata=False, in pooled=True\n",
      "FINAL DATA QUALITY CHECK\n",
      "Total IPOs: 39\n",
      "Complete day1_return: 23\n",
      "Complete car_30: 39\n",
      "Complete vol_30: 39\n",
      "High Subscription: 20\n",
      "Retail-Heavy: 19\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIX TICKER FORMAT INCONSISTENCY (.NS vs .BO)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STANDARDIZING TICKER FORMATS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a function to normalize tickers (remove exchange suffix)\n",
    "def normalize_ticker(ticker):\n",
    "    \"\"\"Remove .NS or .BO suffix to get base ticker\"\"\"\n",
    "    if pd.isna(ticker):\n",
    "        return ticker\n",
    "    return ticker.replace('.NS', '').replace('.BO', '')\n",
    "\n",
    "# Apply to both datasets\n",
    "df['ticker_base'] = df['ticker'].apply(normalize_ticker)\n",
    "df_pooled['ticker_base'] = df_pooled['ticker'].apply(normalize_ticker)\n",
    "\n",
    "print(f\"Metadata unique tickers: {df['ticker_base'].nunique()}\")\n",
    "print(f\"Pooled unique tickers: {df_pooled['ticker_base'].nunique()}\")\n",
    "\n",
    "# Now merge on base ticker instead of full ticker\n",
    "df_final = df.merge(\n",
    "    df_pooled[['ticker_base', 'ticker', 'day1_return', 'car_30', 'vol_30', 'subscription_cat']], \n",
    "    on='ticker_base',\n",
    "    how='inner',\n",
    "    suffixes=('_meta', '_pooled')\n",
    ")\n",
    "\n",
    "# Keep the pooled ticker (with .BO) as the primary since that's what worked with yfinance\n",
    "df_final['ticker'] = df_final['ticker_pooled']\n",
    "\n",
    "print(f\"\\n✓ Merged on base ticker\")\n",
    "print(f\"✓ Final dataset: {len(df_final)} IPOs\")\n",
    "\n",
    "# Verify we got all 40\n",
    "if len(df_final) == 40:\n",
    "    print(\"✓✓ SUCCESS: All 40 IPOs merged!\")\n",
    "elif len(df_final) == 39:\n",
    "    print(f\"⚠️  Still missing 1 IPO - investigating...\")\n",
    "    \n",
    "    # Find which one is still missing\n",
    "    metadata_base = set(df['ticker_base'].unique())\n",
    "    pooled_base = set(df_pooled['ticker_base'].unique())\n",
    "    \n",
    "    missing = pooled_base - set(df_final['ticker_base'].unique())\n",
    "    print(f\"Missing ticker(s): {missing}\")\n",
    "    \n",
    "    # Check if it exists in metadata\n",
    "    for ticker_base in missing:\n",
    "        in_meta = ticker_base in metadata_base\n",
    "        in_pooled = ticker_base in pooled_base\n",
    "        print(f\"{ticker_base}: in metadata={in_meta}, in pooled={in_pooled}\")\n",
    "else:\n",
    "    print(f\"⚠️  Merged {len(df_final)} IPOs (expected 39-40)\")\n",
    "\n",
    "# Final data quality check\n",
    " \n",
    "print(\"FINAL DATA QUALITY CHECK\")\n",
    "print(f\"Total IPOs: {len(df_final)}\")\n",
    "print(f\"Complete day1_return: {df_final['day1_return'].notna().sum()}\")\n",
    "print(f\"Complete car_30: {df_final['car_30'].notna().sum()}\")\n",
    "print(f\"Complete vol_30: {df_final['vol_30'].notna().sum()}\")\n",
    "print(f\"High Subscription: {df_final['high_sub_dummy'].sum()}\")\n",
    "print(f\"Retail-Heavy: {df_final['retail_heavy'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb2e2e6-046e-46c0-bcb4-e99769108570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING MISSING IXIGO IPO TO METADATA\n",
      "IXIGO details from pooled data:\n",
      "company_name          Le Travenues Technology\n",
      "ticker                               IXIGO.NS\n",
      "listing_date              2024-06-18 00:00:00\n",
      "listing_first_date                 2024-06-18\n",
      "day1_return                            0.1155\n",
      "car_30                                 0.0066\n",
      "vol_30                                 0.0384\n",
      "subscription_cat                          Low\n",
      "ticker_base                             IXIGO\n",
      "Name: 34, dtype: object\n"
     ]
    }
   ],
   "source": [
    " print(\"ADDING MISSING IXIGO IPO TO METADATA\")\n",
    " # Get IXIGO details from pooled data\n",
    "ixigo_pooled = df_pooled[df_pooled['ticker_base'] == 'IXIGO'].iloc[0]\n",
    "print(\"IXIGO details from pooled data:\")\n",
    "print(ixigo_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542cd948-a59b-43bc-9dee-a433d5bd2429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Added IXIGO to metadata\n",
      " New metadata size: 40 IPOs\n",
      " Metadata unique tickers: 40\n",
      "\n",
      "================================================================================\n",
      "RE-MERGED DATA QUALITY CHECK\n",
      "Total IPOs: 40 ✓✓ SUCCESS!\n",
      "High Subscription: 20\n",
      "Retail-Heavy: 20\n",
      "\n",
      "Missing day1_return: 16\n"
     ]
    }
   ],
   "source": [
    "ixigo_meta = pd.DataFrame({\n",
    "    'company_name': ['Le Travenues Technology'],\n",
    "    'ticker': ['IXIGO.NS'],  # Add with .NS format to match metadata\n",
    "    'ticker_base': ['IXIGO'],\n",
    "    'listing_date': ['2024-06-18'],\n",
    "    'subscription_category': ['Low'],  # From pooled data\n",
    "    'high_sub_dummy': [0],\n",
    "    'retail_heavy': [1],  # Assume retail-heavy for tech IPO\n",
    "    'issue_size': [df['issue_size'].median()],  # Use median as proxy\n",
    "    'log_issue_size': [np.log(df['issue_size'].median())],\n",
    "    'retail_pct': [55.0],  # Reasonable assumption for Low subscription\n",
    "    'qib_pct': [25.0],\n",
    "    'sector': ['Technology'],\n",
    "    'ipo_year': ['2024'],\n",
    "    'issue_price': [df['issue_price'].median()],\n",
    "    'issue_open': ['2024-06-10'],\n",
    "    'issue_close': ['2024-06-12'],\n",
    "    'qib_pct': [25.0],\n",
    "    'notes': ['Added manually - missing from original metadata']\n",
    "})\n",
    "\n",
    "# Add to df\n",
    "df = pd.concat([df, ixigo_meta], ignore_index=True)\n",
    "\n",
    "print(f\"\\n Added IXIGO to metadata\")\n",
    "print(f\" New metadata size: {len(df)} IPOs\")\n",
    "print(f\" Metadata unique tickers: {df['ticker_base'].nunique()}\")\n",
    "\n",
    "# Now re-merge\n",
    "df['ticker_base'] = df['ticker'].apply(normalize_ticker)\n",
    "\n",
    "df_final = df.merge(\n",
    "    df_pooled[['ticker_base', 'ticker', 'day1_return', 'car_30', 'vol_30', 'subscription_cat']], \n",
    "    on='ticker_base',\n",
    "    how='inner',\n",
    "    suffixes=('_meta', '_pooled')\n",
    ")\n",
    "\n",
    "df_final['ticker'] = df_final['ticker_pooled']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RE-MERGED DATA QUALITY CHECK\")\n",
    "print(f\"Total IPOs: {len(df_final)} {'✓✓ SUCCESS!' if len(df_final) == 40 else 'Check needed'}\")\n",
    "print(f\"High Subscription: {df_final['high_sub_dummy'].sum()}\")\n",
    "print(f\"Retail-Heavy: {df_final['retail_heavy'].sum()}\")\n",
    "print(f\"\\nMissing day1_return: {df_final['day1_return'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9df7c17-48ac-48e1-b03f-2057bec98360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RECALCULATING MISSING DAY1_RETURN VALUES\n",
      "================================================================================\n",
      "MAMATA.NS       - First return:  -0.0500 (day 3)\n",
      "TRANSRAILL.NS   - First return:   0.0036 (day 3)\n",
      "AZAD.NS         - First return:   0.0000 (day -4)\n",
      "ETERNAL.NS      - First return:   0.1163 (day 3)\n",
      "MOTISONS.NS     - First return:  -0.0074 (day -4)\n",
      "PAYTM.NS        - First return:  -0.1289 (day 4)\n",
      "BHARTIHEXA.NS   - First return:  -0.0089 (day 3)\n",
      "SURAJEST.NS     - First return:   0.0385 (day -4)\n",
      "NIVABUPA.NS     - First return:  -0.0196 (day 4)\n",
      "OLAELEC.NS      - First return:   0.2000 (day 3)\n",
      "EASEMYTRIP.NS   - First return:  -0.0518 (day 3)\n",
      "SURAKSHA.NS     - First return:  -0.0157 (day 3)\n",
      "CARTRADE.NS     - First return:   0.0525 (day 3)\n",
      "SANATHAN.NS     - First return:  -0.0521 (day 3)\n",
      "FINOPB.NS       - First return:  -0.0518 (day 3)\n",
      "STANLEY.NS      - First return:   0.0651 (day 3)\n",
      "\n",
      " Recalculated day1_return for 16 IPOs\n",
      "Missing day1_return now: 0\n",
      "UPDATED DATA QUALITY CHECK\n",
      "Total IPOs: 40\n",
      "Complete day1_return: 40 (100.0%)\n",
      "Complete car_30: 40\n",
      "Complete vol_30: 40\n"
     ]
    }
   ],
   "source": [
    "# RECALCULATE MISSING DAY1_RETURN FROM STOCK_MASTER\n",
    " \n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RECALCULATING MISSING DAY1_RETURN VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load stock master\n",
    "STOCK_MASTER_PATH =  \"IPO_Meta/meta_output_processed.csv/df_stock_master.csv\" \n",
    "df_stock = pd.read_csv(STOCK_MASTER_PATH)\n",
    "df_stock['date'] = pd.to_datetime(df_stock['date'])\n",
    "\n",
    "# For each IPO with missing day1_return, get first available ipo_return\n",
    "missing_tickers = df_final[df_final['day1_return'].isnull()]['ticker'].tolist()\n",
    "\n",
    "recalculated = {}\n",
    "for ticker in missing_tickers:\n",
    "    ticker_data = df_stock[df_stock['ticker'] == ticker].sort_values('days_from_listing')\n",
    "    \n",
    "    # Get first non-null ipo_return\n",
    "    first_return = ticker_data[ticker_data['ipo_return'].notna()]['ipo_return'].iloc[0] if len(ticker_data[ticker_data['ipo_return'].notna()]) > 0 else np.nan\n",
    "    first_day = ticker_data[ticker_data['ipo_return'].notna()]['days_from_listing'].iloc[0] if len(ticker_data[ticker_data['ipo_return'].notna()]) > 0 else np.nan\n",
    "    \n",
    "    recalculated[ticker] = {\n",
    "        'day1_return': first_return,\n",
    "        'days_to_first_trade': first_day\n",
    "    }\n",
    "    \n",
    "    print(f\"{ticker:15s} - First return: {first_return:8.4f} (day {first_day})\")\n",
    "\n",
    "# Apply recalculated values to df_final\n",
    "for ticker, values in recalculated.items():\n",
    "    mask = df_final['ticker'] == ticker\n",
    "    df_final.loc[mask, 'day1_return'] = values['day1_return']\n",
    "\n",
    "print(f\"\\n Recalculated day1_return for {len(recalculated)} IPOs\")\n",
    "print(f\"Missing day1_return now: {df_final['day1_return'].isnull().sum()}\")\n",
    "\n",
    "# Verify\n",
    "print(\"UPDATED DATA QUALITY CHECK\")\n",
    "print(f\"Total IPOs: {len(df_final)}\")\n",
    "print(f\"Complete day1_return: {df_final['day1_return'].notna().sum()} ({df_final['day1_return'].notna().sum()/len(df_final)*100:.1f}%)\")\n",
    "print(f\"Complete car_30: {df_final['car_30'].notna().sum()}\")\n",
    "print(f\"Complete vol_30: {df_final['vol_30'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4006f791-5061-4e00-a551-5fa4b1565ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECREATING RETAIL_HEAVY CLASSIFICATION\n",
      "Median retail_pct: 51.17%\n",
      "\n",
      "New classification:\n",
      "  Retail-Heavy (above median): 20\n",
      "  Institutional-Heavy (below median): 20\n",
      "\n",
      "Retail % summary by group:\n",
      "                count      mean      std      min      25%      50%       75%  \\\n",
      "retail_heavy                                                                    \n",
      "0             20.0000    9.1845  15.5818   1.5000   2.2725   2.8000    3.7600   \n",
      "1             20.0000  105.9740  70.0874  52.4700  58.7950  75.5100  133.2300   \n",
      "\n",
      "                   max  \n",
      "retail_heavy            \n",
      "0              49.8700  \n",
      "1             326.9100  \n"
     ]
    }
   ],
   "source": [
    "#Recreating Retail_Heavy Flagging\n",
    "\n",
    " \n",
    "print(\"RECREATING RETAIL_HEAVY CLASSIFICATION\")\n",
    " \n",
    "\n",
    "# Use MEDIAN as threshold (more robust for skewed distribution)\n",
    "median_retail = df_final['retail_pct'].median()\n",
    "print(f\"Median retail_pct: {median_retail:.2f}%\")\n",
    "\n",
    "# Create retail_heavy flag based on median\n",
    "df_final['retail_heavy'] = (df_final['retail_pct'] > median_retail).astype(int)\n",
    "\n",
    "print(f\"\\nNew classification:\")\n",
    "print(f\"  Retail-Heavy (above median): {df_final['retail_heavy'].sum()}\")\n",
    "print(f\"  Institutional-Heavy (below median): {(df_final['retail_heavy']==0).sum()}\")\n",
    "\n",
    "# Verify split is reasonable\n",
    "print(f\"\\nRetail % summary by group:\")\n",
    "print(df_final.groupby('retail_heavy')['retail_pct'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174c52c-18b7-4170-939f-83e498acaf51",
   "metadata": {},
   "source": [
    "5.4  HYPOTHESIS [A] : HIGH SUBSCRIPTION → FIRST-DAY POPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281dc037-8912-47b2-8652-d4ac19159686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPOTHESIS [A]: Do High Subscription IPOs Consistently Show First-Day Pops?\n",
      "\n",
      "---Descriptive Statistics---\n",
      "\n",
      "High Subscription IPOs: 20\n",
      "  Mean First-Day Return: 0.72%\n",
      "  Median: 0.36%\n",
      "  Std. Dev: 5.81%\n",
      "  Positive Returns (Pops): 11 (55.0%)\n",
      "  Range: [-12.89%, 11.63%]\n",
      "\n",
      "Low Subscription IPOs: 20\n",
      "  Mean First-Day Return: 1.43%\n",
      "  Median: -0.94%\n",
      "  Std. Dev: 7.90%\n",
      "  Positive Returns (Pops): 9 (45.0%)\n",
      "  Range: [-7.90%, 20.00%]\n",
      "\n",
      "Mean Difference: -0.71 percentage points\n",
      "\n",
      "Two-Sample T-Test (Welch) : \n",
      "  t-statistic: -0.3243\n",
      "  p-value: 0.7477\n",
      "  Result: NOT SIGNIFICANT at 5% level\n",
      "\n",
      "Mann-Whitney U Test (Robust) : \n",
      "  U-stat: 221.0000\n",
      "  p-value: 0.5792\n",
      "  Result: NOT SIGNIFICANT at 5% level\n",
      "\n",
      "Effect Size (Cohen's d): -0.1025 (Small)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    " \n",
    "\n",
    "print(\"HYPOTHESIS [A]: Do High Subscription IPOs Consistently Show First-Day Pops?\")\n",
    "df_h1 = df_final[df_final['day1_return'].notna()].copy()\n",
    "df_h1['day1_return_pct'] = df_h1['day1_return'] * 100  # Changed: removed underscore\n",
    "\n",
    "# Splitting By Subscription Category\n",
    "high_sub = df_h1[df_h1[\"high_sub_dummy\"] == 1]['day1_return_pct']\n",
    "low_sub = df_h1[df_h1[\"high_sub_dummy\"] == 0]['day1_return_pct']\n",
    "\n",
    "\n",
    "print(f\"\\n---Descriptive Statistics---\")\n",
    "print(f\"\\nHigh Subscription IPOs: {len(high_sub)}\")\n",
    "print(f\"  Mean First-Day Return: {high_sub.mean():.2f}%\")\n",
    "print(f\"  Median: {high_sub.median():.2f}%\")\n",
    "print(f\"  Std. Dev: {high_sub.std():.2f}%\")\n",
    "print(f\"  Positive Returns (Pops): {(high_sub > 0).sum()} ({(high_sub > 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Range: [{high_sub.min():.2f}%, {high_sub.max():.2f}%]\")\n",
    "\n",
    "\n",
    "print(f\"\\nLow Subscription IPOs: {len(low_sub)}\")\n",
    "print(f\"  Mean First-Day Return: {low_sub.mean():.2f}%\")\n",
    "print(f\"  Median: {low_sub.median():.2f}%\")\n",
    "print(f\"  Std. Dev: {low_sub.std():.2f}%\")\n",
    "print(f\"  Positive Returns (Pops): {(low_sub > 0).sum()} ({(low_sub > 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Range: [{low_sub.min():.2f}%, {low_sub.max():.2f}%]\")\n",
    "\n",
    "print(f\"\\nMean Difference: {high_sub.mean() - low_sub.mean():.2f} percentage points\")\n",
    "\n",
    "#STATISTICAL TESTING\n",
    "\n",
    "#Two Sample T Test (Welch, Unequal Variances)\n",
    "t_stat, p_value = stats.ttest_ind(high_sub, low_sub, equal_var= False)\n",
    "print(f\"\\nTwo-Sample T-Test (Welch) : \")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Result: {'SIGNIFICANT' if p_value < 0.05 else 'NOT SIGNIFICANT'} at 5% level\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"   High-Sub IPOs have {\"HIGHER\" if high_sub.mean() > low_sub.mean() else \"LOWER\"} first-day returns\")\n",
    "\n",
    "\n",
    "#Mann-Whitney U Test (non-parametric, robust to outliers)\n",
    "u_stat, p_value_mw = stats.mannwhitneyu(high_sub,low_sub, alternative = 'two-sided')\n",
    "print(f\"\\nMann-Whitney U Test (Robust) : \")\n",
    "print(f\"  U-stat: {u_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value_mw:.4f}\")\n",
    "print(f\"  Result: {'SIGNIFICANT' if p_value_mw < 0.05 else 'NOT SIGNIFICANT'} at 5% level\")\n",
    "\n",
    "#Effect Size (Cohen's D)\n",
    "pooled_std = np.sqrt(((len(high_sub)-1)*high_sub.var() + (len(low_sub)-1)*low_sub.var()) / (len(high_sub) + len(low_sub)-2))\n",
    "cohens_d = (high_sub.mean() - low_sub.mean()) / pooled_std\n",
    "effect_size_label = 'Negligible' if abs(cohens_d) < 0.02 else 'Small' if abs(cohens_d) < 0.5 else 'Medium' if abs(cohens_d) < 0.8 else 'Large'\n",
    "print(f\"\\nEffect Size (Cohen's d): {cohens_d:.4f} ({effect_size_label})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00206a-3b8f-4227-b11d-fb5a2d86f8a5",
   "metadata": {},
   "source": [
    "5.5 HYPOTHESIS [B]: Does Listing Day Premium Sustain Over 30 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "198ec9a9-f3cb-4585-9d5a-12924f18c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPOTHESIS [B]: Does Listing Day Premium Sustain Over 30 days?\n",
      "\n",
      "--- Descriptive Statistics ---\n",
      "\n",
      "IPOs with First-Day Pop (n=20):\n",
      "  Mean First-Day Return: 5.98%\n",
      "  Mean 30-Day CAR: 3.15%\n",
      "  IPOs with Positive 30-Day CAR: 12 (60.0%)\n",
      "  Mean Premium Decay: 2.82%\n",
      "\n",
      "---Statistical Tests ---\n",
      "\n",
      "One-Sample t-Test (H0: 30-day CAR = 0): \n",
      "  t-statistic:  0.9402\n",
      "  p-value: 0.3589\n",
      "  Result: 30-day CAR is NOT SIGNIFICANTLY DIFFERENT FROM 0\n",
      "\n",
      "Paired t-Test (First-Day vs 30 Day):\n",
      "  t-statistic: 0.8949\n",
      "  p-value: 0.3820\n",
      "  Mean Decay: 2.82%\n",
      "  Result: NO SIGNIFICANT DELAY\n",
      "\n",
      "Correlation (First-Day vs 30-Day CAR):\n",
      "  Pearson r: 0.3420\n",
      "  p-value: 0.1400\n",
      "  Result: NOT SIGNIFICANT correlation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "print(\"HYPOTHESIS [B]: Does Listing Day Premium Sustain Over 30 days?\")\n",
    "\n",
    "#Filtering IPOs with positive first-day returns (POPS)\n",
    "df_h2 = df_final[(df_final['day1_return'] > 0) & (df_final['car_30'].notna())].copy()\n",
    "df_h2['day1_return_pct'] = df_h2['day1_return']*100\n",
    "df_h2['car_30_pct'] = df_h2['car_30']*100\n",
    "\n",
    "print(f\"\\n--- Descriptive Statistics ---\")\n",
    "print(f\"\\nIPOs with First-Day Pop (n={len(df_h2)}):\")\n",
    "print(f\"  Mean First-Day Return: {df_h2['day1_return_pct'].mean():.2f}%\")\n",
    "print(f\"  Mean 30-Day CAR: {df_h2['car_30_pct'].mean():.2f}%\")\n",
    "print(f\"  IPOs with Positive 30-Day CAR: {(df_h2['car_30'] > 0).sum()} ({(df_h2['car_30'] > 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Mean Premium Decay: {df_h2['day1_return_pct'].mean() - df_h2['car_30_pct'].mean():.2f}%\")\n",
    "\n",
    "#Statistical Test\n",
    "print(f\"\\n---Statistical Tests ---\")\n",
    "\n",
    "#Test 1: Is 30-Day CAR significantly positive? (one sample t-test against 0)\n",
    "t_stat_30d, p_value_30d = stats.ttest_1samp(df_h2['car_30_pct'],0)\n",
    "print(f\"\\nOne-Sample t-Test (H0: 30-day CAR = 0): \")\n",
    "print(f\"  t-statistic: {t_stat_30d: .4f}\")\n",
    "print(f\"  p-value: {p_value_30d:.4f}\")\n",
    "print(f\"  Result: 30-day CAR is {'SIGNIFICANTLY POSITIVE' if (p_value_30d < 0.05 and df_h2['car_30_pct'].mean() > 0) else 'SIGNIFICANTLY NEGATIVE' if (p_value_30d < 0.05 and df_h2['car_30_pct'].mean() < 0) else 'NOT SIGNIFICANTLY DIFFERENT FROM 0'}\")\n",
    "\n",
    "#Test 2: Does Premium Decay? (Paired t-test: day 1 vs day30)\n",
    "t_stat_paired, p_value_paired = stats.ttest_rel(df_h2['day1_return_pct'], df_h2['car_30_pct'])\n",
    "mean_decay = df_h2['day1_return_pct'].mean() - df_h2['car_30_pct'].mean()\n",
    "print(f\"\\nPaired t-Test (First-Day vs 30 Day):\")\n",
    "print(f\"  t-statistic: {t_stat_paired:.4f}\")\n",
    "print(f\"  p-value: {p_value_paired:.4f}\")\n",
    "print(f\"  Mean Decay: {mean_decay:.2f}%\")\n",
    "print(f\"  Result: {'SIGNIFICANT DECAY' if (p_value_paired < 0.05 and mean_decay > 0) else 'NO SIGNIFICANT DELAY'}\")\n",
    "\n",
    "\n",
    "#Correlation between first day pop and 30 day CAR\n",
    "corr, p_corr = stats.pearsonr(df_h2['day1_return_pct'], df_h2['car_30_pct'])\n",
    "print(f\"\\nCorrelation (First-Day vs 30-Day CAR):\")\n",
    "print(f\"  Pearson r: {corr:.4f}\")\n",
    "print(f\"  p-value: {p_corr:.4f}\")\n",
    "print(f\"  Result: {'SIGNIFICANT' if p_corr < 0.05 else 'NOT SIGNIFICANT'} correlation\")\n",
    "if p_corr < 0.05:\n",
    "     print(f\"  → {'Positive' if corr > 0 else 'Negative'} relationship (higher pops {'sustain' if corr > 0 else 'reverse'})\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e483990-4025-4fbe-a5c6-32b998ab556a",
   "metadata": {},
   "source": [
    "5.6 HYPOTHESIS [C]:  Retail Heavy IPOs More Volatile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e12f12b8-f472-402b-87e0-65cdaf9d3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPOTHESIS [C]: Are Retail-Heavy IPOs More Volatile Post-Listing?\n",
      "\n",
      "--- Descriptive Statistics ---\n",
      "\n",
      "Retail-Heavy IPOs (retail > 50%, n=20):\n",
      "  Mean 30-Day Volatility: 4.72%\n",
      "  Median: 4.83%\n",
      "  Std Dev: 1.48%\n",
      "  Range: 2.10%, 7.14%]\n",
      "\n",
      "Instiutional-Heavy IPOs (retail <= 50%, n=20):\n",
      "  Mean 30-Day Volatility: 4.07%\n",
      "  Median: 4.08%\n",
      "  Std Dev: 1.69%\n",
      "  Range: 1.49%, 7.58%]\n",
      "\n",
      "Mean Difference: 0.64percentage points\n",
      "\n",
      "---Statistical Tests ---\n",
      "\n",
      "Two-Sample t-Test (Welch):\n",
      "  t-statistic: 1.2742\n",
      "  p-value: 0.2105\n",
      "  Result: NOT SIGNIFICANT at 5% level \n",
      "\n",
      "Levene's Test (Variance Equality):\n",
      "  Statistic: 0.0383\n",
      "  p-value: 0.8460\n",
      "  Result: Variances are NOT SIGNIFICANTLY DIFFERENT\n",
      "\n",
      "Effect Size (Cohen's d): 0.4029 (Small)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "print(\"HYPOTHESIS [C]: Are Retail-Heavy IPOs More Volatile Post-Listing?\")\n",
    "\n",
    "#Filtering Valid Data\n",
    "df_h3 = df_final[df_final['vol_30'].notna()].copy()\n",
    "df_h3['vol_30_pct'] = df_h3['vol_30']*100\n",
    "\n",
    "retail_heavy_vol = df_h3[df_h3['retail_heavy'] == 1]['vol_30_pct']\n",
    "retail_light_vol = df_h3[df_h3['retail_heavy'] == 0]['vol_30_pct']\n",
    "\n",
    "print(f\"\\n--- Descriptive Statistics ---\")\n",
    "print(f\"\\nRetail-Heavy IPOs (retail > 50%, n={len(retail_heavy_vol)}):\")\n",
    "print(f\"  Mean 30-Day Volatility: {retail_heavy_vol.mean():.2f}%\")\n",
    "print(f\"  Median: {retail_heavy_vol.median():.2f}%\")\n",
    "print(f\"  Std Dev: {retail_heavy_vol.std():.2f}%\")\n",
    "print(f\"  Range: {retail_heavy_vol.min():.2f}%, {retail_heavy_vol.max():.2f}%]\")\n",
    "\n",
    "print(f\"\\nInstiutional-Heavy IPOs (retail <= 50%, n={len(retail_light_vol)}):\")\n",
    "print(f\"  Mean 30-Day Volatility: {retail_light_vol.mean():.2f}%\")\n",
    "print(f\"  Median: {retail_light_vol.median():.2f}%\")\n",
    "print(f\"  Std Dev: {retail_light_vol.std():.2f}%\")\n",
    "print(f\"  Range: {retail_light_vol.min():.2f}%, {retail_light_vol.max():.2f}%]\")\n",
    "print(f\"\\nMean Difference: {retail_heavy_vol.mean() - retail_light_vol.mean():.2f}percentage points\")\n",
    "\n",
    "\n",
    "#Statistical Test\n",
    "print(f\"\\n---Statistical Tests ---\")\n",
    "\n",
    "#Two Sample t-test\n",
    "t_stat_vol, p_val_vol = stats.ttest_ind(retail_heavy_vol, retail_light_vol, equal_var=False)\n",
    "print(f\"\\nTwo-Sample t-Test (Welch):\")\n",
    "print(f\"  t-statistic: {t_stat_vol:.4f}\")\n",
    "print(f\"  p-value: {p_val_vol:.4f}\")\n",
    "print(f\"  Result: {'SIGNIFCANT' if p_val_vol < 0.05 else 'NOT SIGNIFICANT'} at 5% level \")\n",
    "if p_val_vol < 0.05:\n",
    "    print(f\"  Retail-heavy IPOs are {'MORE' if retail_heavy_vol.mean() > retail_light_vol.mean() else 'LESS'} volatile\")\n",
    "\n",
    "#Levene's test for variance equality (tests if variances differ)\n",
    "levene_stat, p_levene = stats.levene(retail_heavy_vol, retail_light_vol)\n",
    "print(f\"\\nLevene's Test (Variance Equality):\")\n",
    "print(f\"  Statistic: {levene_stat:.4f}\")\n",
    "print(f\"  p-value: {p_levene:.4f}\")\n",
    "print(f\"  Result: Variances are {'SIGNIFICANTLY DIFFERENT' if p_levene < 0.05 else 'NOT SIGNIFICANTLY DIFFERENT'}\")\n",
    "\n",
    "#Effect Size \n",
    "cohens_d_vol = (retail_heavy_vol.mean() - retail_light_vol.mean()) / np.sqrt((retail_heavy_vol.var() + retail_light_vol.var()) / 2)\n",
    "effect_size_label_vol = 'Negligible' if abs(cohens_d_vol) < 0.2 else 'Small' if abs(cohens_d_vol) < 0.5 else 'Medium' if abs(cohens_d_vol) < 0.8 else 'Large'\n",
    "print(f\"\\nEffect Size (Cohen's d): {cohens_d_vol:.4f} ({effect_size_label_vol})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab887ac-d5e7-46c4-9233-c36fb6b9d202",
   "metadata": {},
   "source": [
    "5.7 Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5838e643-865b-4774-b217-e5c7809b869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Hypothesis              Sample Size Test Statistic p-value Significant (α=0.05)    Effect Size\n",
      "        A: High-Sub → First-Day Pop     40 (20 high, 20 low)     t = -0.324  0.7477                 No ✗ -0.103 (Small)\n",
      "        B: Premium Sustains 30 Days           20 (with pops)      t = 0.940  0.3589                 No ✗            N/A\n",
      "C: Retail-Heavy → Higher Volatility 40 (20 retail, 20 inst.)      t = 1.274  0.2105                 No ✗  0.403 (Small)\n",
      "NOTEBOOK_05 COMPLETE ✓\n",
      "Next: Notebook_06 (Visualizations)\n"
     ]
    }
   ],
   "source": [
    "#FINAL SUMMARY\n",
    "summary_results = pd.DataFrame({\n",
    "    'Hypothesis': [\n",
    "        'A: High-Sub → First-Day Pop',\n",
    "        'B: Premium Sustains 30 Days',\n",
    "        'C: Retail-Heavy → Higher Volatility'\n",
    "    ],\n",
    "    'Sample Size': [\n",
    "        f'{len(high_sub) + len(low_sub)} ({len(high_sub)} high, {len(low_sub)} low)',\n",
    "        f'{len(df_h2)} (with pops)',\n",
    "        f'{len(retail_heavy_vol) + len(retail_light_vol)} ({len(retail_heavy_vol)} retail, {len(retail_light_vol)} inst.)'\n",
    "    ],\n",
    "    'Test Statistic': [\n",
    "        f't = {t_stat:.3f}',\n",
    "        f't = {t_stat_30d:.3f}',\n",
    "        f't = {t_stat_vol:.3f}'\n",
    "    ],\n",
    "    'p-value': [\n",
    "       f'{p_value:.4f}',\n",
    "       f'{p_value_30d:.4f}',\n",
    "       f'{p_val_vol:.4f}'\n",
    "    ],\n",
    "    \n",
    "    'Significant (α=0.05)': [\n",
    "        'Yes ✓' if p_value < 0.05 else 'No ✗',\n",
    "        'Yes ✓' if p_value_30d < 0.05 else 'No ✗',\n",
    "        'Yes ✓' if p_val_vol < 0.05 else 'No ✗'  # ← Change this too\n",
    "     ],\n",
    "    'Effect Size': [\n",
    "        f'{cohens_d:.3f} ({effect_size_label})',\n",
    "        'N/A',\n",
    "        f'{cohens_d_vol:.3f} ({effect_size_label_vol})'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(summary_results.to_string(index=False))\n",
    "\n",
    "\n",
    "print(\"NOTEBOOK_05 COMPLETE ✓\")\n",
    "print(\"Next: Notebook_06 (Visualizations)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5705f1f-5870-4952-b6dd-f07478b4f197",
   "metadata": {},
   "source": [
    "5.8 File Ready For Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d4b425a-3a6c-4787-a7ec-693755bd7f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL DATASET SAVED\n",
      "================================================================================\n",
      "Location: IPO_Meta/df_final_for_viz.csv\n",
      "Rows: 40\n",
      "Columns: 23\n",
      "\n",
      "This file contains:\n",
      "  All 40 IPOs with complete data\n",
      "  Metadata (issue_size, retail_pct, sector, etc.)\n",
      "  Returns data (day1_return, car_30, vol_30)\n",
      "  Calculated features (high_sub_dummy, retail_heavy)\n",
      "\n",
      " Ready for Notebook_06 (Visualizations) and Notebook_07 (Report)\n"
     ]
    }
   ],
   "source": [
    "# Save df_final for use in subsequent notebooks\n",
    "df_final.to_csv(\"IPO_Meta/df_final_for_viz.csv\", index=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL DATASET SAVED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Location: IPO_Meta/df_final_for_viz.csv\")\n",
    "print(f\"Rows: {len(df_final)}\")\n",
    "print(f\"Columns: {len(df_final.columns)}\")\n",
    "print(\"\\nThis file contains:\")\n",
    "print(\"  All 40 IPOs with complete data\")\n",
    "print(\"  Metadata (issue_size, retail_pct, sector, etc.)\")\n",
    "print(\"  Returns data (day1_return, car_30, vol_30)\")\n",
    "print(\"  Calculated features (high_sub_dummy, retail_heavy)\")\n",
    "print(\"\\n Ready for Notebook_06 (Visualizations) and Notebook_07 (Report)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c200bf-120c-4237-8a2b-04edbc07e02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900dc9a-2639-4a16-a1fd-113bf315f9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
